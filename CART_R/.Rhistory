setwd("/autofs/unityaccount/cremi/matbechade/TER/CART R")
library(rpart)# Pour l’arbre de décision
library(rpart.plot) # Pour la représentation de l’arbre de décision
#Chargement des données
data = read.csv2("data_big.csv", sep = ",")
#Description des données
summary(data)
data$X2 = as.numeric(data$X2)
data
#Création d’un dataset d’apprentissage et d’un dataset de validation
nb_lignes <- floor((nrow(ptitanic)*0.75)) #Nombre de lignes de l’échantillon d’apprentissage : 75% du dataset
ptitanic <- ptitanic[sample(nrow(ptitanic)), ] #Ajout de numéros de lignes
ptitanic.train <- ptitanic[1:nb_lignes, ] #Echantillon d’apprentissage
ptitanic.test <- ptitanic[(nb_lignes+1):nrow(ptitanic), ] #Echantillon de test
#Construction de l’arbre
data.Tree <- rpart(Y~.,data=data,method= "class", control=rpart.control(minsplit=1,cp=0.5))
#Affichage du résultat
plot(data.Tree, uniform=TRUE, branch=0.5, margin=0.1)
text(data.Tree, all=FALSE, use.n=TRUE)
#On cherche à minimiser l’erreur pour définir le niveau d’élagage
plotcp(data.Tree)
#Affichage du cp optimal
print(data.Tree$cptable[which.min(data.Tree$cptable[,4]),1])
#Elagage de l’arbre avec le cp optimal
data.Tree_Opt <- prune(data.Tree,cp=data.Tree$cptable[which.min(data.Tree$cptable[,4]),1])
prp(data.Tree_Opt,extra=1)
library(rpart)# Pour l’arbre de décision
library(rpart.plot) # Pour la représentation de l’arbre de décision
#Chargement des données
data = read.csv2("data_big.csv", sep = ",")
#Description des données
summary(data)
data$X2 = as.numeric(data$X2)
data
#Création d’un dataset d’apprentissage et d’un dataset de validation
nb_lignes <- floor((nrow(ptitanic)*0.75)) #Nombre de lignes de l’échantillon d’apprentissage : 75% du dataset
ptitanic <- ptitanic[sample(nrow(ptitanic)), ] #Ajout de numéros de lignes
ptitanic.train <- ptitanic[1:nb_lignes, ] #Echantillon d’apprentissage
ptitanic.test <- ptitanic[(nb_lignes+1):nrow(ptitanic), ] #Echantillon de test
#Construction de l’arbre
data.Tree <- rpart(Y~.,data=data,method= "class", control=rpart.control(minsplit=1,cp=0.01))
#Affichage du résultat
plot(data.Tree, uniform=TRUE, branch=0.5, margin=0.1)
text(data.Tree, all=FALSE, use.n=TRUE)
#On cherche à minimiser l’erreur pour définir le niveau d’élagage
plotcp(data.Tree)
#Affichage du cp optimal
print(data.Tree$cptable[which.min(data.Tree$cptable[,4]),1])
#Elagage de l’arbre avec le cp optimal
data.Tree_Opt <- prune(data.Tree,cp=data.Tree$cptable[which.min(data.Tree$cptable[,4]),1])
prp(data.Tree_Opt,extra=1)
#Construction de l’arbre
data.Tree <- rpart(Y~.,data=data,method= "class", control=rpart.control(minsplit=1,cp=0.01))
#Affichage du résultat
plot(data.Tree, uniform=TRUE, branch=0.5, margin=0.1)
text(data.Tree, all=FALSE, use.n=TRUE)
#Construction de l’arbre
data.Tree <- rpart(Y~.,data=data,method= "class", control=rpart.control(minsplit=1,cp=0.01))
#Affichage du résultat
plot(data.Tree, uniform=TRUE, branch=0.5, margin=0.1)
text(data.Tree, all=FALSE, use.n=TRUE)
library(rpart)# Pour l’arbre de décision
library(rpart.plot) # Pour la représentation de l’arbre de décision
#Chargement des données
data = read.csv2("data_big.csv", sep = ",")
#Description des données
summary(data)
data$X2 = as.numeric(data$X2)
data
#Création d’un dataset d’apprentissage et d’un dataset de validation
nb_lignes <- floor((nrow(ptitanic)*0.75)) #Nombre de lignes de l’échantillon d’apprentissage : 75% du dataset
ptitanic <- ptitanic[sample(nrow(ptitanic)), ] #Ajout de numéros de lignes
ptitanic.train <- ptitanic[1:nb_lignes, ] #Echantillon d’apprentissage
ptitanic.test <- ptitanic[(nb_lignes+1):nrow(ptitanic), ] #Echantillon de test
#Construction de l’arbre
data.Tree <- rpart(Y~.,data=data,method= "class", control=rpart.control(minsplit=1,cp=0.001))
#Affichage du résultat
plot(data.Tree, uniform=TRUE, branch=0.5, margin=0.1)
text(data.Tree, all=FALSE, use.n=TRUE)
#On cherche à minimiser l’erreur pour définir le niveau d’élagage
plotcp(data.Tree)
#Affichage du cp optimal
print(data.Tree$cptable[which.min(data.Tree$cptable[,4]),1])
#Elagage de l’arbre avec le cp optimal
data.Tree_Opt <- prune(data.Tree,cp=data.Tree$cptable[which.min(data.Tree$cptable[,4]),1])
prp(data.Tree_Opt,extra=1)
data.Tree <- rpart(Y~.,data=data,method= "class", control=rpart.control(minsplit=1,cp=0.001))
#Affichage du résultat
plot(data.Tree, uniform=TRUE, branch=0.5, margin=0.1)
text(data.Tree, all=FALSE, use.n=TRUE)
#Construction de l’arbre
data.Tree <- rpart(Y~.,data=data,method= "class", control=rpart.control(minsplit=1,cp=0.0000001))
#Affichage du résultat
plot(data.Tree, uniform=TRUE, branch=0.5, margin=0.1)
text(data.Tree, all=FALSE, use.n=TRUE)
#Construction de l’arbre
data.Tree <- rpart(Y~.,data=data,method= "class", control=rpart.control(minsplit=1,cp=1))
#Affichage du résultat
plot(data.Tree, uniform=TRUE, branch=0.5, margin=0.1)
text(data.Tree, all=FALSE, use.n=TRUE)
#Construction de l’arbre
data.Tree <- rpart(Y~.,data=data,method= "class", control=rpart.control(minsplit=1,cp=100))
#Affichage du résultat
plot(data.Tree, uniform=TRUE, branch=0.5, margin=0.1)
text(data.Tree, all=FALSE, use.n=TRUE)
#Construction de l’arbre
data.Tree <- rpart(Y~.,data=data,method= "class", control=rpart.control(minsplit=1,cp=100))
#Affichage du résultat
plot(data.Tree, uniform=TRUE, branch=0.5, margin=0.1)
text(data.Tree, all=FALSE, use.n=TRUE)
data.Tree <- rpart(Y~.,data=data,method= "class", control=rpart.control(minsplit=1,cp=3))
#Affichage du résultat
plot(data.Tree, uniform=TRUE, branch=0.5, margin=0.1)
text(data.Tree, all=FALSE, use.n=TRUE)
data.Tree <- rpart(Y~.,data=data,method= "class", control=rpart.control(minsplit=1,cp=0.9))
#Affichage du résultat
plot(data.Tree, uniform=TRUE, branch=0.5, margin=0.1)
text(data.Tree, all=FALSE, use.n=TRUE)
#Construction de l’arbre
data.Tree <- rpart(Y~.,data=data,method= "class", control=rpart.control(minsplit=1,cp=0.1))
#Affichage du résultat
plot(data.Tree, uniform=TRUE, branch=0.5, margin=0.1)
text(data.Tree, all=FALSE, use.n=TRUE)
data.Tree <- rpart(Y~.,data=data,method= "class", control=rpart.control(minsplit=1,cp=0))
#Affichage du résultat
plot(data.Tree, uniform=TRUE, branch=0.5, margin=0.1)
text(data.Tree, all=FALSE, use.n=TRUE)
#Elagage de l’arbre avec le cp optimal
data.Tree_Opt <- prune(data.Tree,cp=data.Tree$cptable[which.min(data.Tree$cptable[,4]),1])
prp(data.Tree_Opt,extra=1)
library(rpart)# Pour l’arbre de décision
library(rpart.plot) # Pour la représentation de l’arbre de décision
#Chargement des données
data("ptitanic")
#Description des données
summary(ptitanic)
#Création d’un dataset d’apprentissage et d’un dataset de validation
nb_lignes <- floor((nrow(ptitanic)*0.75)) #Nombre de lignes de l’échantillon d’apprentissage : 75% du dataset
ptitanic <- ptitanic[sample(nrow(ptitanic)), ] #Ajout de numéros de lignes
ptitanic.train <- ptitanic[1:nb_lignes, ] #Echantillon d’apprentissage
ptitanic.test <- ptitanic[(nb_lignes+1):nrow(ptitanic), ] #Echantillon de test
#Construction de l’arbre
ptitanic.Tree <- rpart(survived~.,data=ptitanic.train,method= "class", control=rpart.control(minsplit=5,cp=0))
#Affichage du résultat
plot(ptitanic.Tree, uniform=TRUE, branch=0.5, margin=0.1)
text(ptitanic.Tree, all=FALSE, use.n=TRUE)
#On cherche à minimiser l’erreur pour définir le niveau d’élagage
plotcp(ptitanic.Tree)
#Affichage du cp optimal
print(ptitanic.Tree$cptable[which.min(ptitanic.Tree$cptable[,4]),1])
#Elagage de l’arbre avec le cp optimal
ptitanic.Tree_Opt <- prune(ptitanic.Tree,cp=ptitanic.Tree$cptable[which.min(ptitanic.Tree$cptable[,4]),1])
prp(ptitanic.Tree_Opt,extra=1)
View(ptitanic)
library(rpart)# Pour l’arbre de décision
library(rpart.plot) # Pour la représentation de l’arbre de décision
#Chargement des données
data = read.csv2("data_bigbig.csv", sep = ",")
#Description des données
summary(data)
data$X2 = as.numeric(data$X2)
data
#Construction de l’arbre
data.Tree <- rpart(Y~.,data=data,method= "class", control=rpart.control(minsplit=1,cp=0))
#Affichage du résultat
plot(data.Tree, uniform=TRUE, branch=0.5, margin=0.1)
text(data.Tree, all=FALSE, use.n=TRUE)
#On cherche à minimiser l’erreur pour définir le niveau d’élagage
plotcp(data.Tree)
#Affichage du cp optimal
print(data.Tree$cptable[which.min(data.Tree$cptable[,4]),1])
#Elagage de l’arbre avec le cp optimal
data.Tree_Opt <- prune(data.Tree,cp=data.Tree$cptable[which.min(data.Tree$cptable[,4]),1])
prp(data.Tree_Opt,extra=1)
data.Tree <- rpart(Y~.,data=data,method= "class", control=rpart.control(minsplit=1,cp=0))
#Affichage du résultat
plot(data.Tree, uniform=TRUE, branch=0.5, margin=0.1)
text(data.Tree, all=FALSE, use.n=TRUE)
#Construction de l’arbre
data.Tree <- rpart(Y~.,data=data,method= "class", control=rpart.control(minsplit=1,cp=0))
#Affichage du résultat
plot(data.Tree, uniform=TRUE, branch=0.5, margin=0.1)
text(data.Tree, all=TRUE, use.n=TRUE)
data.Tree <- rpart(Y~.,data=data,method= "class", control=rpart.control(minsplit=1,cp=0))
#Affichage du résultat
plot(data.Tree, uniform=TRUE, branch=0.5, margin=0.1)
text(data.Tree, all=TRUE, use.n=TRUE)
prp(data.Tree, extra=1)
prp(data.Tree_Opt,extra=1)
