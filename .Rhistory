# Charger les bibliothèques nécessaires
library(rpart)
library(rpart.plot)
library(caret)
# Lire les données à partir d'un fichier CSV
data <- read.csv("data.csv")
# Diviser les données en ensembles d'entraînement et de test
set.seed(123)
train_index <- createDataPartition(data$Y, p=0.8, list=FALSE)
train_data <- data[train_index, ]
test_data <- data[-train_index, ]
# Construire l'arbre de décision en utilisant l'indice de Gini
arbre_decision <- rpart(Y ~ X1 + X2, data=train_data, method="class", parms=list(split="gini"))
# Afficher l'arbre de décision
rpart.plot(arbre_decision, type=4, extra=2)
View(data)
View(data)
View(test_data)
View(train_data)
# Charger les bibliothèques nécessaires
library(rpart)
library(rpart.plot)
library(caret)
# Lire le fichier CSV
data <- read.csv("data.csv")
# Diviser les données en ensembles d'entraînement et de test
set.seed(123)
train_index <- createDataPartition(data$Y, p=0.8, list=FALSE)
train_data <- data[train_index, ]
# Construire l'arbre de décision avec rpart
arbre_decision_rpart <- rpart(Y ~ X1 + X2, data=train_data, method="class", parms=list(split="gini"))
# Afficher l'arbre de décision
rpart.plot(arbre_decision_rpart, type=3, box.palette="auto", shadow.col="gray", nn=TRUE)
# Charger les bibliothèques nécessaires
library(rpart)
library(rpart.plot)
library(caret)
# Lire le fichier CSV
data <- read.csv("data.csv")
# Diviser les données en ensembles d'entraînement et de test
set.seed(123)
train_index <- createDataPartition(data$Y, p=0.8, list=FALSE)
train_data <- data[train_index, ]
# Construire l'arbre de décision avec rpart et un paramètre cp plus petit
arbre_decision_rpart <- rpart(Y ~ X1 + X2, data=train_data, method="class", parms=list(split="gini"), control=rpart.control(cp=0.001))
# Afficher l'arbre de décision
rpart.plot(arbre_decision_rpart, type=3, box.palette="auto", shadow.col="gray", nn=TRUE)
# Charger les bibliothèques nécessaires
library(rpart)
library(rpart.plot)
library(caret)
# Lire le fichier CSV
data <- read.csv("data.csv")
# Diviser les données en ensembles d'entraînement et de test
set.seed(123)
train_index <- createDataPartition(data$Y, p=0.8, list=FALSE)
train_data <- data[train_index, ]
# Construire l'arbre de décision avec rpart et un paramètre cp plus petit
arbre_decision_rpart <- rpart(Y ~ X1 + X2, data=train_data, method="class", parms=list(split="gini"), control=rpart.control(cp=0.001))
# Afficher l'arbre de décision
rpart.plot(arbre_decision_rpart, type=3, box.palette="auto", shadow.col="gray", nn=TRUE)
View(arbre_decision_rpart)
View(arbre_decision_rpart)
View(data)
View(data)
# Charger les bibliothèques nécessaires
library(rpart)
library(rpart.plot)
library(caret)
# Lire le fichier CSV
data <- read.csv("data.csv")
# Diviser les données en ensembles d'entraînement et de test
set.seed(123)
train_index <- createDataPartition(data$Y, p=0.9, list=FALSE)
train_data <- data[train_index, ]
# Construire l'arbre de décision avec rpart et un paramètre cp plus petit
arbre_decision_rpart <- rpart(Y ~ X1 + X2, data=train_data, method="class", parms=list(split="gini"), control=rpart.control(cp=0.001))
# Afficher l'arbre de décision
rpart.plot(arbre_decision_rpart, type=3, box.palette="auto", shadow.col="gray", nn=TRUE)
# Charger les bibliothèques nécessaires
library(rpart)
library(rpart.plot)
library(caret)
# Lire le fichier CSV
data <- read.csv("data.csv")
# Diviser les données en ensembles d'entraînement et de test
set.seed(123)
train_index <- createDataPartition(data$Y, p=1, list=FALSE)
train_data <- data[train_index, ]
# Construire l'arbre de décision avec rpart et un paramètre cp plus petit
arbre_decision_rpart <- rpart(Y ~ X1 + X2, data=train_data, method="class", parms=list(split="gini"), control=rpart.control(cp=0.001))
# Afficher l'arbre de décision
rpart.plot(arbre_decision_rpart, type=3, box.palette="auto", shadow.col="gray", nn=TRUE)
# Charger les bibliothèques nécessaires
library(rpart)
library(rpart.plot)
library(caret)
# Lire le fichier CSV
data <- read.csv("data.csv")
# Diviser les données en ensembles d'entraînement et de test
set.seed(123)
train_index <- createDataPartition(data$Y, p=0.6, list=FALSE)
train_data <- data[train_index, ]
# Construire l'arbre de décision avec rpart et un paramètre cp plus petit
arbre_decision_rpart <- rpart(Y ~ X1 + X2, data=train_data, method="class", parms=list(split="gini"), control=rpart.control(cp=0.001))
# Afficher l'arbre de décision
rpart.plot(arbre_decision_rpart, type=3, box.palette="auto", shadow.col="gray", nn=TRUE)
# Charger les bibliothèques nécessaires
library(rpart)
library(rpart.plot)
library(caret)
# Lire le fichier CSV
data <- read.csv("data_1.csv")
# Diviser les données en ensembles d'entraînement et de test
set.seed(123)
train_index <- createDataPartition(data$Y, p=0.6, list=FALSE)
train_data <- data[train_index, ]
# Construire l'arbre de décision avec rpart et un paramètre cp plus petit
arbre_decision_rpart <- rpart(Y ~ X1 + X2, data=train_data, method="class", parms=list(split="gini"), control=rpart.control(cp=0.001))
# Afficher l'arbre de décision
rpart.plot(arbre_decision_rpart, type=3, box.palette="auto", shadow.col="gray", nn=TRUE)
# Charger les bibliothèques nécessaires
library(rpart)
library(rpart.plot)
library(caret)
# Lire le fichier CSV
data <- read.csv("data_1.csv")
# Diviser les données en ensembles d'entraînement et de test
set.seed(123)
train_index <- createDataPartition(data$Y, p=0.8, list=FALSE)
train_data <- data[train_index, ]
# Construire l'arbre de décision avec rpart et un paramètre cp plus petit
arbre_decision_rpart <- rpart(Y ~ X1 + X2, data=train_data, method="class", parms=list(split="gini"), control=rpart.control(cp=0.001))
# Afficher l'arbre de décision
rpart.plot(arbre_decision_rpart, type=3, box.palette="auto", shadow.col="gray", nn=TRUE)
# Charger les bibliothèques nécessaires
library(rpart)
library(rpart.plot)
library(caret)
# Lire le fichier CSV
data <- read.csv("data_1.csv")
# Diviser les données en ensembles d'entraînement et de test
set.seed(123)
train_index <- createDataPartition(data$Y, p=0.6, list=FALSE)
train_data <- data[train_index, ]
# Construire l'arbre de décision avec rpart et un paramètre cp plus petit
arbre_decision_rpart <- rpart(Y ~ X1 + X2, data=train_data, method="class", parms=list(split="gini"), control=rpart.control(cp=0.001))
# Afficher l'arbre de décision
rpart.plot(arbre_decision_rpart, type=3, box.palette="auto", shadow.col="gray", nn=TRUE)
# Charger les bibliothèques nécessaires
library(rpart)
library(rpart.plot)
library(caret)
# Lire le fichier CSV
data <- read.csv("data_1.csv")
# Diviser les données en ensembles d'entraînement et de test
set.seed(123)
train_index <- createDataPartition(data$Y, p=0.5, list=FALSE)
train_data <- data[train_index, ]
# Construire l'arbre de décision avec rpart et un paramètre cp plus petit
arbre_decision_rpart <- rpart(Y ~ X1 + X2, data=train_data, method="class", parms=list(split="gini"), control=rpart.control(cp=0.001))
# Afficher l'arbre de décision
rpart.plot(arbre_decision_rpart, type=3, box.palette="auto", shadow.col="gray", nn=TRUE)
# Charger les bibliothèques nécessaires
library(rpart)
library(rpart.plot)
library(caret)
# Lire le fichier CSV
data <- read.csv("data_1.csv")
# Diviser les données en ensembles d'entraînement et de test
set.seed(123)
train_index <- createDataPartition(data$Y, p=0.7, list=FALSE)
train_data <- data[train_index, ]
# Construire l'arbre de décision avec rpart et un paramètre cp plus petit
arbre_decision_rpart <- rpart(Y ~ X1 + X2, data=train_data, method="class", parms=list(split="gini"), control=rpart.control(cp=0.001))
# Afficher l'arbre de décision
rpart.plot(arbre_decision_rpart, type=3, box.palette="auto", shadow.col="gray", nn=TRUE)
# Charger les bibliothèques nécessaires
library(rpart)
library(rpart.plot)
library(caret)
# Lire le fichier CSV
data <- read.csv("data_1.csv")
# Diviser les données en ensembles d'entraînement et de test
set.seed(123)
train_index <- createDataPartition(data$Y, p=0.7, list=FALSE)
train_data <- data[train_index, ]
# Construire l'arbre de décision avec rpart et un paramètre cp plus petit
arbre_decision_rpart <- rpart(Y ~ X1 + X2, data=train_data, method="class", parms=list(split="gini"), control=rpart.control(cp=0.1))
# Afficher l'arbre de décision
rpart.plot(arbre_decision_rpart, type=3, box.palette="auto", shadow.col="gray", nn=TRUE)
# Charger les bibliothèques nécessaires
library(rpart)
library(rpart.plot)
library(caret)
# Lire le fichier CSV
data <- read.csv("data_1.csv")
# Diviser les données en ensembles d'entraînement et de test
set.seed(123)
train_index <- createDataPartition(data$Y, p=0.7, list=FALSE)
train_data <- data[train_index, ]
# Construire l'arbre de décision avec rpart et un paramètre cp plus petit
arbre_decision_rpart <- rpart(Y ~ X1 + X2, data=train_data, method="class", parms=list(split="gini"), control=rpart.control(cp=0.001))
# Afficher l'arbre de décision
rpart.plot(arbre_decision_rpart, type=3, box.palette="auto", shadow.col="gray", nn=TRUE)
# Charger les bibliothèques nécessaires
library(rpart)
library(rpart.plot)
library(caret)
# Lire le fichier CSV
data <- read.csv("data.csv")
# Diviser les données en ensembles d'entraînement et de test
set.seed(123)
train_index <- createDataPartition(data$Y, p=0.7, list=FALSE)
train_data <- data[train_index, ]
# Construire l'arbre de décision avec rpart et un paramètre cp plus petit
arbre_decision_rpart <- rpart(Y ~ X1 + X2, data=train_data, method="class", parms=list(split="gini"), control=rpart.control(cp=0.001))
# Afficher l'arbre de décision
rpart.plot(arbre_decision_rpart, type=3, box.palette="auto", shadow.col="gray", nn=TRUE)
# Charger les bibliothèques nécessaires
library(rpart)
library(rpart.plot)
library(caret)
# Lire le fichier CSV
data <- read.csv("data.csv")
# Diviser les données en ensembles d'entraînement et de test
set.seed(123)
train_index <- createDataPartition(data$Y, p=0.7, list=FALSE)
train_data <- data[train_index, ]
# Construire l'arbre de décision avec rpart et un paramètre cp plus petit
arbre_decision_rpart <- rpart(Y ~ X1 + X2, data=train_data, method="class", parms=list(split="gini"), control=rpart.control(cp=0.001))
# Afficher l'arbre de décision
rpart.plot(arbre_decision_rpart, type=3, box.palette="auto", shadow.col="gray", nn=TRUE)
summary(arbre_decision_rpart)
library(partykit)
party_arbre <- as.party(arbre_decision_rpart)
plot(party_arbre)
# Charger les bibliothèques nécessaires
library(rpart)
library(rpart.plot)
library(caret)
# Lire le fichier CSV
data <- read.csv("data.csv")
# Diviser les données en ensembles d'entraînement et de test
set.seed(123)
train_index <- createDataPartition(data$Y, p=0.5, list=FALSE)
train_data <- data[train_index, ]
# Construire l'arbre de décision avec rpart et un paramètre cp plus petit
arbre_decision_rpart <- rpart(Y ~ X1 + X2, data=train_data, method="class", parms=list(split="gini"), control=rpart.control(cp=0.001))
# Afficher l'arbre de décision
rpart.plot(arbre_decision_rpart, type=3, box.palette="auto", shadow.col="gray", nn=TRUE)
summary(arbre_decision_rpart)
library(partykit)
party_arbre <- as.party(arbre_decision_rpart)
plot(party_arbre)
# Charger les bibliothèques nécessaires
library(rpart)
library(rpart.plot)
library(caret)
# Lire le fichier CSV
data <- read.csv("data.csv")
# Diviser les données en ensembles d'entraînement et de test
set.seed(123)
train_index <- createDataPartition(data$Y, p=0.5, list=FALSE)
train_data <- data[train_index, ]
# Construire l'arbre de décision avec rpart et un paramètre cp plus petit
arbre_decision_rpart <- rpart(Y ~ X1 + X2, data=train_data, method="class", parms=list(split="gini"), control=rpart.control(cp=0.001))
# Afficher l'arbre de décision
rpart.plot(arbre_decision_rpart, type=3, box.palette="auto", shadow.col="gray", nn=TRUE)
# Charger les bibliothèques nécessaires
library(rpart)
library(rpart.plot)
library(caret)
# Lire le fichier CSV
data <- read.csv("data.csv")
# Diviser les données en ensembles d'entraînement et de test
set.seed(123)
train_index <- createDataPartition(data$Y, p=0.5, list=FALSE)
train_data <- data[train_index, ]
# Construire l'arbre de décision avec rpart et un paramètre cp plus petit
arbre_decision_rpart <- rpart(Y ~ X1 + X2, data=train_data, method="class", parms=list(split="gini"), control=rpart.control(cp=0.001))
# Afficher l'arbre de décision
rpart.plot(arbre_decision_rpart, type=3, box.palette="auto", shadow.col="gray", nn=TRUE)
summary(arbre_decision_rpart)
library(partykit)
party_arbre <- as.party(arbre_decision_rpart)
plot(party_arbre)
# Charger les bibliothèques nécessaires
library(rpart)
library(rpart.plot)
library(caret)
# Installer et charger les bibliothèques nécessaires
library(party)
install.packages("party")
# Charger les bibliothèques nécessaires
library(rpart)
library(rpart.plot)
library(caret)
# Installer et charger les bibliothèques nécessaires
library(party)
# Charger les données
data <- read.csv("data.csv")
# Construire l'arbre de décision avec la méthode ctree (conditional inference tree)
arbre_decision_ctree <- ctree(Y ~ X1 + X2, data=data)
# Charger les bibliothèques nécessaires
library(rpart)
library(rpart.plot)
library(caret)
# Installer et charger les bibliothèques nécessaires
library(party)
# Charger les données
data <- read.csv("data.csv")
# Construire l'arbre de décision avec la méthode ctree (conditional inference tree)
arbre_decision_ctree <- ctree(Y ~ X1 + X2, data=data)
View(data)
View(data)
# Charger les bibliothèques nécessaires
library(rpart)
library(rpart.plot)
library(caret)
library(party)
# Charger les données
data <- read.csv("data.csv")
# Convertir la colonne Y en facteur
data$Y <- as.factor(data$Y)
# Construire l'arbre de décision avec la méthode ctree (conditional inference tree)
arbre_decision_ctree <- ctree(Y ~ X1 + X2, data=data)
# Afficher l'arbre de décision
plot(arbre_decision_ctree)
View(arbre_decision_ctree)
View(arbre_decision_ctree)
# Charger les bibliothèques nécessaires
library(rpart)
library(rpart.plot)
library(caret)
# Charger les bibliothèques nécessaires
library(party)
library(partykit)
# Charger les données
data <- read.csv("data.csv")
# Convertir la colonne Y en facteur
data$Y <- as.factor(data$Y)
# Construire l'arbre de décision avec la méthode ctree (conditional inference tree)
arbre_decision_ctree <- ctree(Y ~ X1 + X2, data=data)
# Convertir l'objet ctree en objet party
arbre_decision_party <- as.party(arbre_decision_ctree)
# Charger les bibliothèques nécessaires
library(rpart)
library(rpart.plot)
library(caret)
# Charger les bibliothèques nécessaires
library(party)
library(partykit)
# Charger les données
data <- read.csv("data.csv")
# Convertir la colonne Y en facteur
data$Y <- as.factor(data$Y)
# Construire l'arbre de décision avec la méthode ctree (conditional inference tree)
arbre_decision_ctree <- ctree(Y ~ X1 + X2, data=data)
# Afficher l'arbre de décision avec la fonction plot() de la bibliothèque partykit
plot(arbre_decision_ctree)
# Charger les bibliothèques nécessaires
library(rpart)
library(rpart.plot)
# Charger les données
data <- read.csv("data.csv")
# Convertir la colonne Y en facteur
data$Y <- as.factor(data$Y)
# Construire l'arbre de décision avec la méthode rpart
arbre_decision_rpart <- rpart(Y ~ X1 + X2, data=data, method="class", parms=list(split="gini"))
# Afficher l'arbre de décision étape par étape
rpart.plot(arbre_decision_rpart, type=4, extra=101, fallen.leaves=FALSE, under=TRUE)
# Charger les bibliothèques nécessaires
library(rpart)
library(rpart.plot)
# Charger les données
data <- read.csv("data.csv")
# Convertir la colonne Y en facteur
data$Y <- as.factor(data$Y)
# Construire l'arbre de décision avec la méthode rpart
arbre_decision_rpart <- rpart(Y ~ X1 + X2, data=data, method="class", parms=list(split="gini"), control=rpart.control(cp=0.01))
# Afficher l'arbre de décision étape par étape
rpart.plot(arbre_decision_rpart, type=4, extra=101, fallen.leaves=FALSE, under=TRUE)
# Charger les bibliothèques nécessaires
library(rpart)
library(rpart.plot)
# Lire le fichier CSV
data <- read.csv("data.csv")
# Construire l'arbre de décision avec rpart et un paramètre cp plus petit
arbre_decision_rpart <- rpart(Y ~ X1 + X2, data=data, method="class", parms=list(split="gini"), control=rpart.control(cp=0.001))
# Afficher l'arbre de décision avec prp
prp(arbre_decision_rpart, type=0, extra=1, under=TRUE, fallen.leaves=TRUE, varlen=0, faclen=0)
# Charger les bibliothèques nécessaires
library(rpart)
library(plotly)
# Lire le fichier CSV
data <- read.csv("data.csv")
# Construire l'arbre de décision avec rpart et un paramètre cp plus petit
arbre_decision_rpart <- rpart(Y ~ X1 + X2, data=data, method="class", parms=list(split="gini"), control=rpart.control(cp=0.001))
# Fonction pour convertir un arbre rpart en un format compatible avec plotly
rpart_to_plotly <- function(tree) {
n <- length(tree$frame)
tree$frame$id <- 1:n
p <- plotly::plot_ly(
type = "scatter",
mode = "text",
text = tree$frame$var,
hoverinfo = "text",
textposition = "middle center"
)
for (i in 1:(n - 1)) {
if (is.na(tree$frame$yval[i])) {
yval <- paste(tree$frame$yval2[i, ], collapse = ", ")
} else {
yval <- tree$frame$yval[i]
}
p <- plotly::add_trace(
p, type = "scatter",
mode = "text",
text = paste0("X1 <= ", round(tree$frame$split[i], 2), "<br>",
"n = ", tree$frame$n[i], "<br>",
"y = ", yval),
hoverinfo = "text",
textposition = "middle left"
)
}
p
}
# Utiliser la fonction pour afficher l'arbre de décision avec plotly
rpart_plotly <- rpart_to_plotly(arbre_decision_rpart)
# Charger les bibliothèques nécessaires
library(rpart)
library(rattle)
# Lire le fichier CSV
data <- read.csv("data.csv")
# Construire l'arbre de décision avec rpart et un paramètre cp plus petit
arbre_decision_rpart <- rpart(Y ~ X1 + X2, data=data, method="class", parms=list(split="gini"), control=rpart.control(cp=0.001))
# Afficher l'arbre de décision avec fancyRpartPlot
fancyRpartPlot(arbre_decision_rpart, caption = NULL)
# Charger les bibliothèques nécessaires
library(rpart)
library(rattle)
# Lire le fichier CSV
data <- read.csv("data.csv")
# Construire l'arbre de décision avec rpart et un paramètre cp plus petit
arbre_decision_rpart <- rpart(Y ~ X1 + X2, data=data, method="class", parms=list(split="gini"), control=rpart.control(cp=0.001))
# Afficher l'arbre de décision avec fancyRpartPlot
fancyRpartPlot(arbre_decision_rpart, caption = NULL)
# Charger les bibliothèques nécessaires
library(rpart)
library(rpart.plot)
# Lire le fichier CSV
data <- read.csv("data.csv")
# Construire l'arbre de décision avec rpart et un paramètre cp plus petit
arbre_decision_rpart <- rpart(Y ~ X1 + X2, data=data, method="class", parms=list(split="gini"), control=rpart.control(cp=0.001))
# Afficher l'arbre de décision avec rpart.plot
rpart.plot(arbre_decision_rpart, type=3, box.palette="auto", shadow.col="gray", nn=TRUE)
# Charger les bibliothèques nécessaires
library(rpart)
library(rpart.plot)
# Lire le fichier CSV
data <- read.csv("data.csv")
# Construire l'arbre de décision avec rpart et un paramètre cp plus petit
arbre_decision_rpart <- rpart(Y ~ X1 + X2, data=data, method="class", parms=list(split="gini"), control=rpart.control(cp=0.001))
# Afficher l'arbre de décision avec prp
prp(arbre_decision_rpart, type=0, extra=1, under=TRUE, fallen.leaves=TRUE, varlen=0, faclen=0)
# Charger les bibliothèques nécessaires
library(rpart)
library(rpart.plot)
# Charger les données
data <- read.csv("data.csv")
# Convertir la colonne Y en facteur
data$Y <- as.factor(data$Y)
# Construire l'arbre de décision avec la méthode rpart
arbre_decision_rpart <- rpart(Y ~ X1 + X2, data=data, method="class", parms=list(split="gini"), control=rpart.control(cp=0.01))
# Afficher l'arbre de décision étape par étape
rpart.plot(arbre_decision_rpart, type=4, extra=101, fallen.leaves=FALSE, under=TRUE)
# Charger les bibliothèques nécessaires
library(rpart)
library(rpart.plot)
# Charger les données
data <- read.csv("data.csv")
# Convertir la colonne Y en facteur
data$Y <- as.factor(data$Y)
# Construire l'arbre de décision avec la méthode rpart
arbre_decision_rpart <- rpart(Y ~ X1 + X2, data=data, method="class", parms=list(split="gini"), control=rpart.control(minsplit=5, cp=0.01))
# Afficher l'arbre de décision étape par étape
rpart.plot(arbre_decision_rpart, type=4, extra=101, fallen.leaves=FALSE, under=TRUE)
# Charger les bibliothèques nécessaires
library(rpart)
library(rpart.plot)
# Charger les données
data <- read.csv("data.csv")
# Convertir la colonne Y en facteur
data$Y <- as.factor(data$Y)
# Construire l'arbre de décision avec la méthode rpart
arbre_decision_rpart <- rpart(Y ~ X1 + X2, data=data, method="class", parms=list(split="gini"), control=rpart.control(minsplit=10, cp=0.01))
# Afficher l'arbre de décision étape par étape
rpart.plot(arbre_decision_rpart, type=4, extra=101, fallen.leaves=FALSE, under=TRUE)
# Construire l'arbre de décision avec la méthode rpart
arbre_decision_rpart <- rpart(Y ~ X1 + X2, data=data, method="class", parms=list(split="gini"), control=rpart.control(minsplit=1, cp=0.01))
# Charger les bibliothèques nécessaires
library(rpart)
library(rpart.plot)
# Charger les données
data <- read.csv("data.csv")
# Convertir la colonne Y en facteur
data$Y <- as.factor(data$Y)
# Construire l'arbre de décision avec la méthode rpart
arbre_decision_rpart <- rpart(Y ~ X1 + X2, data=data, method="class", parms=list(split="gini"), control=rpart.control(minsplit=1, cp=0.01))
# Afficher l'arbre de décision étape par étape
rpart.plot(arbre_decision_rpart, type=4, extra=101, fallen.leaves=FALSE, under=TRUE)
